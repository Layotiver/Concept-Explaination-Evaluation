{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6, 7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "from ud_treebank_utils.reader import UDTreebankReader\n",
    "from os import path\n",
    "from config import cfg as default_cfg\n",
    "from utils import *\n",
    "\n",
    "cfg = default_cfg\n",
    "device = cfg['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank: /data2/zhihao/intrinsic-probing/data/ud/ud-treebanks-v2.1/UD_English/en-um-train-bert-base-multilingual-cased.pkl\n",
      "Valid Treebank: /data2/zhihao/intrinsic-probing/data/ud/ud-treebanks-v2.1/UD_English/en-um-dev-bert-base-multilingual-cased.pkl\n",
      "Test Treebank: /data2/zhihao/intrinsic-probing/data/ud/ud-treebanks-v2.1/UD_English/en-um-test-bert-base-multilingual-cased.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create Reader for English UD Treebank\n",
    "treebank       = UDTreebankReader.get_treebank_file(cfg['language'], embedding=cfg['embedding'])\n",
    "treebank_valid = UDTreebankReader.get_treebank_file(cfg['language'], embedding=cfg['embedding'], valid_file=True)\n",
    "treebank_test  = UDTreebankReader.get_treebank_file(cfg['language'], embedding=cfg['embedding'], test_file=True)\n",
    "\n",
    "print(f\"Treebank: {treebank}\")\n",
    "print(f\"Valid Treebank: {treebank_valid}\")\n",
    "print(f\"Test Treebank: {treebank_test}\")\n",
    "\n",
    "words = UDTreebankReader.read([treebank])\n",
    "# 一个词和它对应的属性的值 Shaikh({'Number': 'SG', 'Part of Speech': 'PROPN'})\n",
    "words_valid = UDTreebankReader.read([treebank_valid])\n",
    "words_test = UDTreebankReader.read([treebank_test])\n",
    "\n",
    "counters = [\n",
    "    UDTreebankReader.get_attribute_value_counter(words),\n",
    "    UDTreebankReader.get_attribute_value_counter(words_valid),\n",
    "    UDTreebankReader.get_attribute_value_counter(words_test)\n",
    "]\n",
    "\n",
    "attr_vals_dict = UDTreebankReader.get_attributes_to_values_dict_from_counters(counters, min_count=100)\n",
    "# 字典: 要探测的属性的类别与值\n",
    "# {'Number': ['SG', 'PL'], 'Part of Speech': ['PROPN', 'ADJ', 'N', 'V', 'V.PTCP', 'NUM', 'ADV'], 'Tense': ['PST', 'PRS']}\n",
    "\n",
    "reader = UDTreebankReader(words, attr_vals_dict)\n",
    "reader_valid = UDTreebankReader(words_valid, attr_vals_dict)\n",
    "reader_test = UDTreebankReader(words_test, attr_vals_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building caches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Build Cache:   0%|          | 0/3 [00:00<?, ?it/s]/home/zhihao/Concept-Explaination-Evaluation/ud_treebank_utils/trainer.py:126: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)\n",
      "  embeddings_scatter_prior = (embeddings_mean - self.mu) @ (embeddings_mean - self.mu).T\n",
      "Build Cache: 100%|██████████| 3/3 [00:12<00:00,  4.27s/it]\n",
      "Build Cache: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n",
      "Build Cache: 100%|██████████| 3/3 [00:06<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes queue: ['Number', 'Tense']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ud_treebank_utils.cache import AttributeValueGaussianCache\n",
    "from ud_treebank_utils.trainer import MLETrainer, MAPTrainer\n",
    "\n",
    "print(\"Building caches...\")\n",
    "if cfg['trainer'] == \"mle\":\n",
    "    trainer = MLETrainer()\n",
    "elif cfg['trainer'] == \"map\":\n",
    "    trainer = MAPTrainer.from_data(device=device)\n",
    "\n",
    "cache_attr_vals_dict = attr_vals_dict\n",
    "\n",
    "cache = AttributeValueGaussianCache(\n",
    "    reader.get_words(), trainer=trainer, attribute_values_dict=cache_attr_vals_dict, diagonal_only=cfg['diagonalize'])\n",
    "cache_valid = AttributeValueGaussianCache(\n",
    "    reader_valid.get_words(), trainer=trainer, attribute_values_dict=cache_attr_vals_dict, diagonal_only=cfg['diagonalize'])\n",
    "cache_test = AttributeValueGaussianCache(\n",
    "    reader_test.get_words(), trainer=trainer, attribute_values_dict=cache_attr_vals_dict, diagonal_only=cfg['diagonalize'])\n",
    "\n",
    "if cfg['attribute'] is not None:\n",
    "    attributes_queue = [cfg['attribute']]\n",
    "else:\n",
    "    attributes_queue = list(attr_vals_dict.keys())\n",
    "\n",
    "    ignore_list = [\"Part of Speech\"]\n",
    "    attributes_queue = [x for x in attributes_queue if x not in ignore_list]\n",
    "\n",
    "print(f\"Attributes queue: {attributes_queue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MI for 'Number'. Possible values: ['SG', 'PL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/768 [00:00<?, ?it/s]/home/zhihao/Concept-Explaination-Evaluation/ud_treebank_utils/reader.py:179: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "\n",
      "100%|██████████| 768/768 [00:19<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '387'\n",
      "\tI(H_[387]; V_a): 0.04658160232393693\n",
      "\tAccuracy: 0.8424102067947388\n",
      "\tConfusion Matrix: \n",
      "[[7208, 58], [1302, 62]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [00:17<00:00, 44.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '160'\n",
      "\tI(H_[160, 387]; V_a): 0.0941754299385682\n",
      "\tAccuracy: 0.8412514328956604\n",
      "\tConfusion Matrix: \n",
      "[[7039, 227], [1143, 221]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [00:21<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '453'\n",
      "\tI(H_[160, 387, 453]; V_a): 0.13157073437588895\n",
      "\tAccuracy: 0.8524913191795349\n",
      "\tConfusion Matrix: \n",
      "[[7000, 266], [1007, 357]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 765/765 [00:26<00:00, 28.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '450'\n",
      "\tI(H_[160, 450, 387, 453]; V_a): 0.17018872043860606\n",
      "\tAccuracy: 0.8626883029937744\n",
      "\tConfusion Matrix: \n",
      "[[6949, 317], [868, 496]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:25<00:00, 29.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '223'\n",
      "\tI(H_[160, 450, 387, 453, 223]; V_a): 0.20026389471371775\n",
      "\tAccuracy: 0.874275803565979\n",
      "\tConfusion Matrix: \n",
      "[[6967, 299], [786, 578]]\n",
      "\n",
      "Full Vector Accuracy: 0.9646582007408142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhihao/Concept-Explaination-Evaluation/ud_treebank_utils/graph_writer.py:77: UserWarning:\n",
      "\n",
      "torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1692.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MI for 'Tense'. Possible values: ['PST', 'PRS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 768/768 [00:09<00:00, 80.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '477'\n",
      "\tI(H_[477]; V_a): 0.17616291681608764\n",
      "\tAccuracy: 0.7048412561416626\n",
      "\tConfusion Matrix: \n",
      "[[740, 241], [326, 614]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [00:14<00:00, 52.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '179'\n",
      "\tI(H_[179, 477]; V_a): 0.3174778493891156\n",
      "\tAccuracy: 0.771473228931427\n",
      "\tConfusion Matrix: \n",
      "[[813, 168], [271, 669]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [00:18<00:00, 40.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '753'\n",
      "\tI(H_[753, 179, 477]; V_a): 0.44033135860377326\n",
      "\tAccuracy: 0.8172826766967773\n",
      "\tConfusion Matrix: \n",
      "[[802, 179], [172, 768]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 765/765 [00:25<00:00, 30.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '464'\n",
      "\tI(H_[464, 753, 179, 477]; V_a): 0.4808665583377604\n",
      "\tAccuracy: 0.8375846147537231\n",
      "\tConfusion Matrix: \n",
      "[[826, 155], [157, 783]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 764/764 [00:25<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected '554'\n",
      "\tI(H_[464, 753, 179, 554, 477]; V_a): 0.542170257108153\n",
      "\tAccuracy: 0.8599687814712524\n",
      "\tConfusion Matrix: \n",
      "[[855, 126], [143, 797]]\n",
      "\n",
      "Full Vector Accuracy: 0.985424280166626\n"
     ]
    }
   ],
   "source": [
    "from ud_treebank_utils.models import ValueModel\n",
    "from ud_treebank_utils.runner import Runner\n",
    "\n",
    "for attribute in attributes_queue:\n",
    "    # 安全检查\n",
    "    if not cache.has_attribute(attribute):\n",
    "        print(f\"Attribute '{attribute}' does not exist in this dataset/language combination.\")\n",
    "        exit()\n",
    "    \n",
    "    if len(cache.get_all_attribute_values(attribute)) < 2:\n",
    "        print(f\"Attribute '{attribute}' has less that 2 values in this dataset/language combination.\")\n",
    "        exit()\n",
    "\n",
    "    if cfg['log_wandb'] is True:  \n",
    "        import wandb\n",
    "        tags = [cfg['language'], cfg['embedding'], attribute]\n",
    "        cfg['attribute'] = attribute\n",
    "        if cfg['tag'] is not None:\n",
    "            tags.append(cfg['tag'])\n",
    "\n",
    "        run = wandb.init(project=\"interp-bert\", tags=tags, config=cfg, reinit=True)  # 原代码中使用的是config=args, 所以wandb可能不可用?\n",
    "        run.name = f\"{attribute} ({cfg['embedding']}-{cfg['language']}) (\"\n",
    "        if cfg['diagonalize']:\n",
    "            run.name += f\"{cfg['selection_criterion']}, diag)\"\n",
    "        else:\n",
    "            run.name += f\"{cfg['selection_criterion']})\"\n",
    "\n",
    "        run.name += f\" [{wandb.run.id}]\"\n",
    "        run.save()\n",
    "\n",
    "    print(\"Computing MI for '{}'. Possible values: {}\".format(\n",
    "            attribute, cache.get_all_attribute_values(attribute)))\n",
    "    \n",
    "    # 创建Value Model\n",
    "    attribute_values = cache.get_all_attribute_values(attribute) # list: 对应属性的所有可能值 ['SG', 'PL']\n",
    "\n",
    "    value_model = ValueModel.from_cache_entries(\n",
    "        [cache.get_cache_entry(attribute, v) for v in attribute_values], device=device\n",
    "    )\n",
    "\n",
    "    value_model_valid = ValueModel.from_cache_entries(\n",
    "        [cache_valid.get_cache_entry(attribute, v) for v in attribute_values], device=device\n",
    "    )\n",
    "\n",
    "    value_model_test = ValueModel.from_cache_entries(\n",
    "        [cache_test.get_cache_entry(attribute, v) for v in attribute_values], device=device\n",
    "    )\n",
    "\n",
    "    runner_config = {\n",
    "        \"reader\": reader,\n",
    "        \"reader_valid\": reader_valid,\n",
    "        \"reader_test\": reader_test,\n",
    "        \"device\": device,\n",
    "        \"cache\": cache,\n",
    "        \"cache_valid\": cache_valid,\n",
    "        \"cache_test\": cache_test,\n",
    "        \"value_model\": value_model,\n",
    "        \"value_model_valid\": value_model_valid,\n",
    "        \"value_model_test\": value_model_test,\n",
    "        \"attribute\": attribute,\n",
    "        \"selection_criterion\": cfg['selection_criterion'],\n",
    "    }\n",
    "\n",
    "    if cfg['log_wandb'] is True:\n",
    "        runner_config[\"wandb_run\"] = run\n",
    "\n",
    "    total_dims = reader.get_dimensionality() # 768\n",
    "    runner = Runner(runner_config)\n",
    "    selected_results = runner.main_loop(max_iter=cfg['max_iter'])\n",
    "    \n",
    "    # Draw graphs\n",
    "    graphs = runner.draw_graphs(selected_results)\n",
    "    mi_fig = graphs[\"mi\"]\n",
    "    normalized_mi_fig = graphs[\"normalized_mi\"]\n",
    "    accuracy_fig = graphs[\"accuracy\"]\n",
    "    scatter_fig = runner.plot_dims(\n",
    "        selected_results[0][\"candidate_dim\"], selected_results[1][\"candidate_dim\"], test_data=True,\n",
    "        log_prob_dim_pool=list(selected_results[-1][\"candidate_dim_pool\"])\n",
    "    )\n",
    "\n",
    "    \n",
    "    if cfg['show_charts'] is True:\n",
    "        mi_fig.show()\n",
    "        normalized_mi_fig.show()\n",
    "        accuracy_fig.show()\n",
    "        scatter_fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xxx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
